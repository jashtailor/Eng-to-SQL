{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "jumbo_nb",
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2022-03-08T17:03:01.821050Z",
          "iopub.execute_input": "2022-03-08T17:03:01.821313Z",
          "iopub.status.idle": "2022-03-08T17:03:01.832022Z",
          "shell.execute_reply.started": "2022-03-08T17:03:01.821283Z",
          "shell.execute_reply": "2022-03-08T17:03:01.831071Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uanmLSJzhJCB",
        "outputId": "bda65da6-05e7-4ae3-f018-8d8d860faec8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# importing the necessary libaries\n",
        "import os, sys\n",
        "\n",
        "import tensorflow\n",
        "from tensorflow import keras\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, GRU, Dense, Embedding\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np \n",
        "from numpy import array\n",
        "from numpy import asarray\n",
        "from numpy import zeros\n",
        "import pandas as pd \n",
        "import re\n",
        "from tqdm import tqdm\n",
        " \n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "en_stop = set(nltk.corpus.stopwords.words('english'))\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "stemmer = WordNetLemmatizer()\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        " \n",
        "from gensim.models.fasttext import FastText\n",
        "\n",
        "import h5py\n",
        "from keras.models import model_from_json\n",
        "import json"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-08T17:03:01.837385Z",
          "iopub.execute_input": "2022-03-08T17:03:01.837806Z",
          "iopub.status.idle": "2022-03-08T17:03:01.843599Z",
          "shell.execute_reply.started": "2022-03-08T17:03:01.837773Z",
          "shell.execute_reply": "2022-03-08T17:03:01.842852Z"
        },
        "trusted": true,
        "id": "l5jWG5fnhJCF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "941afe7f-66a8-4f95-cd32-d72098ea8393"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# defining the values of various parameters\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 20\n",
        "LSTM_NODES = 256\n",
        "NUM_SENTENCES = 10000\n",
        "MAX_SENTENCE_LENGTH = 50\n",
        "MAX_NUM_WORDS = 20000\n",
        "EMBEDDING_SIZE = 100\n",
        "number = 7000"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-08T17:03:01.844814Z",
          "iopub.execute_input": "2022-03-08T17:03:01.845127Z",
          "iopub.status.idle": "2022-03-08T17:03:01.852967Z",
          "shell.execute_reply.started": "2022-03-08T17:03:01.845092Z",
          "shell.execute_reply": "2022-03-08T17:03:01.852192Z"
        },
        "trusted": true,
        "id": "HTOom29chJCG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defining the lists for encoder and decoder inputs and decoder output\n",
        "input_sentences = [] # encoder input\n",
        "output_sentences = [] # decoder output\n",
        "output_sentences_inputs = [] # decoder input"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-08T17:03:01.854327Z",
          "iopub.execute_input": "2022-03-08T17:03:01.854660Z",
          "iopub.status.idle": "2022-03-08T17:03:01.864029Z",
          "shell.execute_reply.started": "2022-03-08T17:03:01.854625Z",
          "shell.execute_reply": "2022-03-08T17:03:01.863255Z"
        },
        "trusted": true,
        "id": "wF5wt5OKhJCG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/final year project /jumbo_trials/wikisql_v3.csv')\n",
        "df.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "zJFORUctbimZ",
        "outputId": "4a138c87-b595-4c98-ff6d-c3c2d6e5b17b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            question  \\\n",
              "0    What number is the player that played 1998-2001   \n",
              "1       What time was the highest for 2nd finishers?   \n",
              "2      how many times is the fuel propulsion is cng?   \n",
              "3  When did the Metrostars have their first Rooki...   \n",
              "4  What is the number of chapters listed for the ...   \n",
              "\n",
              "                                                 sql  \n",
              "0  SELECT MIN No. FROM table WHERE Years in Toron...  \n",
              "1                          SELECT MAX 2nd FROM table  \n",
              "2  SELECT COUNT Fleet Series (Quantity) FROM tabl...  \n",
              "3  SELECT MIN Season FROM table WHERE Team = Metr...  \n",
              "4  SELECT MAX Chapters FROM table WHERE Classific...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-32d6b7c7-ea70-434e-95fd-7fa894b111c3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>sql</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What number is the player that played 1998-2001</td>\n",
              "      <td>SELECT MIN No. FROM table WHERE Years in Toron...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What time was the highest for 2nd finishers?</td>\n",
              "      <td>SELECT MAX 2nd FROM table</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>how many times is the fuel propulsion is cng?</td>\n",
              "      <td>SELECT COUNT Fleet Series (Quantity) FROM tabl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>When did the Metrostars have their first Rooki...</td>\n",
              "      <td>SELECT MIN Season FROM table WHERE Team = Metr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What is the number of chapters listed for the ...</td>\n",
              "      <td>SELECT MAX Chapters FROM table WHERE Classific...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-32d6b7c7-ea70-434e-95fd-7fa894b111c3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-32d6b7c7-ea70-434e-95fd-7fa894b111c3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-32d6b7c7-ea70-434e-95fd-7fa894b111c3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Aje3yTSkl4s",
        "outputId": "d4572c96-9d22-4882-b613-d492fc172bbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7500, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# input_sentences list will be fed in the encoder LSTM\n",
        "# output_sentences_inputs list will be fed in the decoder LSTM\n",
        "# output_sentences list will be the output of the decoder LSTM\n",
        "# appending english elements in the input_sentences list\n",
        "# adding <eos> tag to the end of the sql elements and appending them to the output_sentences list\n",
        "# adding <sos> tag to the start of the sql elements and appending them to the output_sentences_inputs list\n",
        "\n",
        "input_sentences = df['question']\n",
        "\n",
        "for each in df['sql']:\n",
        "  output_sentence = each + ' <eos>'\n",
        "  output_sentence_input = '<sos> ' + each\n",
        "  output_sentences.append(output_sentence)\n",
        "  output_sentences_inputs.append(output_sentence_input)"
      ],
      "metadata": {
        "id": "wvKkJjrscR8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# printing the lengths of each list\n",
        "print(\"Number samples input:\", len(input_sentences))\n",
        "print(\"Number samples output:\", len(output_sentences))\n",
        "print(\"Number samples output input:\", len(output_sentences_inputs))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-08T17:03:01.953053Z",
          "iopub.execute_input": "2022-03-08T17:03:01.953431Z",
          "iopub.status.idle": "2022-03-08T17:03:01.959593Z",
          "shell.execute_reply.started": "2022-03-08T17:03:01.953387Z",
          "shell.execute_reply": "2022-03-08T17:03:01.958860Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a53yUkjHhJCH",
        "outputId": "562df008-3eff-4818-9850-ee8d4cf250ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number samples input: 7500\n",
            "Number samples output: 7500\n",
            "Number samples output input: 7500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# printing a random record from all 3 lists\n",
        "i = np.random.choice(len(input_sentences))\n",
        "print(input_sentences[i])\n",
        "print(output_sentences[i])\n",
        "print(output_sentences_inputs[i])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-08T17:03:01.960767Z",
          "iopub.execute_input": "2022-03-08T17:03:01.961403Z",
          "iopub.status.idle": "2022-03-08T17:03:01.969162Z",
          "shell.execute_reply.started": "2022-03-08T17:03:01.961366Z",
          "shell.execute_reply": "2022-03-08T17:03:01.968478Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idRSAyyohJCI",
        "outputId": "5d69b60d-ec35-4071-ced7-07650d74a727"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is the % similarity to C7orf38 of the animal whose % identity to C7orf38 is 81?\n",
            "SELECT MAX % Similarity to C7orf38 FROM table WHERE % Identity to C7orf38 = 81 <eos>\n",
            "<sos> SELECT MAX % Similarity to C7orf38 FROM table WHERE % Identity to C7orf38 = 81\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''# due to computational reasons\n",
        "input_sentences = input_sentences\n",
        "output_sentences = output_sentences\n",
        "output_sentences_inputs = output_sentences_inputs'''"
      ],
      "metadata": {
        "id": "4VUPhx8-8eC9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4dc3506b-f558-4c93-9504-c535ae3715c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'# due to computational reasons\\ninput_sentences = input_sentences\\noutput_sentences = output_sentences\\noutput_sentences_inputs = output_sentences_inputs'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# initializing tokenizer and passing input_sentences through them \n",
        "# tokenizer divides a sentence into the corresponding list of word\n",
        "# then it converts the words to integers\n",
        "# text_to_sequences substitutes words for their corresponding integer values\n",
        "# the word_index attribute of the Tokenizer class returns a word-to-index dictionary where words are the keys and the corresponding integers are the values\n",
        "# this just prints the value of the longest input sentence\n",
        "\n",
        "# encoder\n",
        "input_tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
        "input_tokenizer.fit_on_texts(input_sentences)\n",
        "input_integer_seq = input_tokenizer.texts_to_sequences(input_sentences)\n",
        "\n",
        "word2idx_inputs = input_tokenizer.word_index\n",
        "'''\n",
        "count = max(word2idx_inputs.values())\n",
        "for each in words:\n",
        "  word2idx_inputs[each] = count\n",
        "  count = count + 1\n",
        "'''\n",
        "\n",
        "print('Total unique words in the input: %s' % len(word2idx_inputs))\n",
        "\n",
        "max_input_len = max(len(sen) for sen in input_integer_seq)\n",
        "print(\"Length of longest sentence in input: %g\" % max_input_len)\n",
        "\n",
        "print('\\n')\n",
        "\n",
        "# decoder\n",
        "output_tokenizer = Tokenizer(num_words=MAX_NUM_WORDS, filters='')\n",
        "output_tokenizer.fit_on_texts(output_sentences + output_sentences_inputs)\n",
        "output_integer_seq = output_tokenizer.texts_to_sequences(output_sentences)\n",
        "output_input_integer_seq = output_tokenizer.texts_to_sequences(output_sentences_inputs)\n",
        "\n",
        "word2idx_outputs = output_tokenizer.word_index\n",
        "'''\n",
        "count = max(word2idx_outputs.values())\n",
        "for each in words:\n",
        "  word2idx_outputs[each] = count\n",
        "  count = count + 1\n",
        "'''\n",
        "\n",
        "print('Total unique words in the output: %s' % len(word2idx_outputs))\n",
        "\n",
        "num_words_output = len(word2idx_outputs) + 1\n",
        "max_out_len = max(len(sen) for sen in output_integer_seq)\n",
        "print(\"Length of longest sentence in the output: %g\" % max_out_len)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-08T17:03:01.970340Z",
          "iopub.execute_input": "2022-03-08T17:03:01.970823Z",
          "iopub.status.idle": "2022-03-08T17:03:02.516101Z",
          "shell.execute_reply.started": "2022-03-08T17:03:01.970786Z",
          "shell.execute_reply": "2022-03-08T17:03:02.515428Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kxd-hYIrhJCI",
        "outputId": "18472d66-ae21-45f4-c165-ad854009f5c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total unique words in the input: 9001\n",
            "Length of longest sentence in input: 46\n",
            "\n",
            "\n",
            "Total unique words in the output: 10005\n",
            "Length of longest sentence in the output: 58\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_integer_seq = input_integer_seq\n",
        "print('Total unique words in the input: %s' % len(word2idx_inputs))\n",
        "\n",
        "max_input_len = max(len(sen) for sen in input_integer_seq)\n",
        "print(\"Length of longest sentence in input: %g\" % max_input_len)\n",
        "\n",
        "print('\\n')\n",
        "\n",
        "output_integer_seq = output_integer_seq\n",
        "output_input_integer_seq = output_input_integer_seq\n",
        "\n",
        "print('Total unique words in the output: %s' % len(word2idx_outputs))\n",
        "\n",
        "num_words_output = len(word2idx_outputs) + 1\n",
        "max_out_len = max(len(sen) for sen in output_integer_seq)\n",
        "print(\"Length of longest sentence in the output: %g\" % max_out_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvurTR6W5ikI",
        "outputId": "13d2b87a-01a5-4e87-b996-0a598352cfaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total unique words in the input: 9001\n",
            "Length of longest sentence in input: 46\n",
            "\n",
            "\n",
            "Total unique words in the output: 10005\n",
            "Length of longest sentence in the output: 58\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# here the lists made by text_to_sequences is padded to make them all equal in size \n",
        "\n",
        "# encoder input\n",
        "encoder_input_sequences = pad_sequences(input_integer_seq, maxlen=max_input_len)\n",
        "print(\"encoder_input_sequences.shape:\", encoder_input_sequences.shape)\n",
        "print(\"encoder_input_sequences[172]:\", encoder_input_sequences[172])\n",
        "\n",
        "print('\\n')\n",
        "\n",
        "# decoder input\n",
        "decoder_input_sequences = pad_sequences(output_input_integer_seq, maxlen=max_out_len, padding='post')\n",
        "print(\"decoder_input_sequences.shape:\", decoder_input_sequences.shape)\n",
        "print(\"decoder_input_sequences[172]:\", decoder_input_sequences[172])\n",
        "\n",
        "print('\\n')\n",
        "\n",
        "# decoder output\n",
        "decoder_output_sequences = pad_sequences(output_integer_seq, maxlen=max_out_len, padding='post')\n",
        "print(\"decoder_input_sequences.shape:\", decoder_output_sequences.shape)\n",
        "print(\"decoder_input_sequences[172]:\", decoder_output_sequences[172])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-08T17:03:03.305216Z",
          "iopub.execute_input": "2022-03-08T17:03:03.305869Z",
          "iopub.status.idle": "2022-03-08T17:03:03.394559Z",
          "shell.execute_reply.started": "2022-03-08T17:03:03.305832Z",
          "shell.execute_reply": "2022-03-08T17:03:03.393867Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "viLNmQw9hJCK",
        "outputId": "c5533295-6982-4e32-c027-bddfb82b95e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoder_input_sequences.shape: (7500, 46)\n",
            "encoder_input_sequences[172]: [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   3   2   1\n",
            "  78 973  46  82 974 723   2 132 272 869]\n",
            "\n",
            "\n",
            "decoder_input_sequences.shape: (7500, 58)\n",
            "decoder_input_sequences[172]: [  7   3   9 795   1   2   5  19 707 355   4 184 185 796   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0]\n",
            "\n",
            "\n",
            "decoder_input_sequences.shape: (7500, 58)\n",
            "decoder_input_sequences[172]: [  3   9 795   1   2   5  19 707 355   4 184 185 796   6   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_words_output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CK8W--926zsk",
        "outputId": "9b9bea80-70cb-4ca9-e894-05285584f3b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10006"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the GloVE embeddings\n",
        "'''\n",
        "GloVe, coined from Global Vectors, is a model for distributed word representation. \n",
        "The model is an unsupervised learning algorithm for obtaining vector representations for words. \n",
        "This is achieved by mapping words into a meaningful space where the distance between words is related to semantic similarity\n",
        "'''\n",
        "\n",
        "embeddings_dictionary = dict()\n",
        "# words = []\n",
        "\n",
        "glove_file = open(r'/content/drive/MyDrive/final year project /glove.6B.100d.txt', encoding=\"utf8\")\n",
        "\n",
        "for line in glove_file:\n",
        "    records = line.split()\n",
        "    word = records[0]\n",
        "    # words.append(word)\n",
        "    vector_dimensions = asarray(records[1:], dtype='float32')\n",
        "    embeddings_dictionary[word] = vector_dimensions\n",
        "glove_file.close()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-08T17:03:03.632385Z",
          "iopub.execute_input": "2022-03-08T17:03:03.632881Z",
          "iopub.status.idle": "2022-03-08T17:03:15.604692Z",
          "shell.execute_reply.started": "2022-03-08T17:03:03.632845Z",
          "shell.execute_reply": "2022-03-08T17:03:15.603916Z"
        },
        "trusted": true,
        "id": "F2kQDNBBhJCN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# finding out the values for each word in our dataset from the GloVE embeddings\n",
        "num_words = max(MAX_NUM_WORDS, len(word2idx_inputs) + 1)\n",
        "embedding_matrix = zeros((num_words, EMBEDDING_SIZE))\n",
        "for word, index in word2idx_inputs.items():\n",
        "    embedding_vector = embeddings_dictionary.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[index] = embedding_vector"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-08T17:03:15.606091Z",
          "iopub.execute_input": "2022-03-08T17:03:15.606339Z",
          "iopub.status.idle": "2022-03-08T17:03:15.619441Z",
          "shell.execute_reply.started": "2022-03-08T17:03:15.606307Z",
          "shell.execute_reply": "2022-03-08T17:03:15.618742Z"
        },
        "trusted": true,
        "id": "BzylY1k2hJCP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defining the embedding layer\n",
        "embedding_layer = Embedding(num_words, EMBEDDING_SIZE, weights=[embedding_matrix], input_length=max_input_len)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-08T17:03:15.638921Z",
          "iopub.execute_input": "2022-03-08T17:03:15.639188Z",
          "iopub.status.idle": "2022-03-08T17:03:15.646185Z",
          "shell.execute_reply.started": "2022-03-08T17:03:15.639147Z",
          "shell.execute_reply": "2022-03-08T17:03:15.645462Z"
        },
        "trusted": true,
        "id": "AnVh7vuuhJCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To make predictions, the final layer of the model will be a dense layer, \n",
        "# therefore we need the outputs in the form of one-hot encoded vectors, \n",
        "# since we will be using softmax activation function at the dense layer. \n",
        "# To create such one-hot encoded output, the next step is to assign 1 to the column number that corresponds to the integer representation of the word.\n",
        "\n",
        "decoder_targets_one_hot = np.zeros((\n",
        "        len(input_sentences),\n",
        "        max_out_len,\n",
        "        num_words_output\n",
        "    ),\n",
        "    dtype=np.uint16\n",
        ")\n",
        "\n",
        "print(decoder_targets_one_hot.shape)\n",
        "\n",
        "for i, d in enumerate(decoder_output_sequences):\n",
        "    for t, word in enumerate(d):\n",
        "        decoder_targets_one_hot[i, t, word] = 1"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-08T17:03:15.648941Z",
          "iopub.execute_input": "2022-03-08T17:03:15.649136Z",
          "iopub.status.idle": "2022-03-08T17:03:15.654596Z",
          "shell.execute_reply.started": "2022-03-08T17:03:15.649114Z",
          "shell.execute_reply": "2022-03-08T17:03:15.653916Z"
        },
        "trusted": true,
        "id": "d1rUkMa0hJCU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d63efc5c-0bac-43e9-b563-5ed32978f3b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7500, 58, 10006)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# defining the encoder\n",
        "# the embedding layer output is passed through the LSTM nodes\n",
        "# The input to the encoder will be the sentence in English and the output will be the hidden state and cell state of the LSTM.\n",
        "\n",
        "encoder_inputs_placeholder = Input(shape=(max_input_len,))\n",
        "x = embedding_layer(encoder_inputs_placeholder)\n",
        "encoder = LSTM(LSTM_NODES, return_state=True)\n",
        "\n",
        "encoder_outputs, h, c = encoder(x)\n",
        "encoder_states = [h, c]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-08T17:03:16.704457Z",
          "iopub.execute_input": "2022-03-08T17:03:16.706034Z",
          "iopub.status.idle": "2022-03-08T17:03:17.472676Z",
          "shell.execute_reply.started": "2022-03-08T17:03:16.705990Z",
          "shell.execute_reply": "2022-03-08T17:03:17.471930Z"
        },
        "trusted": true,
        "id": "7JgXjFx_hJCX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The decoder will have two inputs: the hidden state and cell state from the encoder and the input sentence, which actually will be the output sentence with an <sos> token appended at the beginning.\n",
        "\n",
        "decoder_inputs_placeholder = Input(shape=(max_out_len,))\n",
        "\n",
        "decoder_embedding = Embedding(num_words_output, LSTM_NODES)\n",
        "decoder_inputs_x = decoder_embedding(decoder_inputs_placeholder)\n",
        "\n",
        "decoder_lstm = LSTM(LSTM_NODES, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs_x, initial_state=encoder_states)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-08T17:03:17.476620Z",
          "iopub.execute_input": "2022-03-08T17:03:17.476839Z",
          "iopub.status.idle": "2022-03-08T17:03:17.689973Z",
          "shell.execute_reply.started": "2022-03-08T17:03:17.476814Z",
          "shell.execute_reply": "2022-03-08T17:03:17.689193Z"
        },
        "trusted": true,
        "id": "QN0Fo-4uhJCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the output from the decoder LSTM is passed through a dense layer to predict decoder outputs\n",
        "\n",
        "decoder_dense = Dense(num_words_output, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-08T17:03:17.693172Z",
          "iopub.execute_input": "2022-03-08T17:03:17.693368Z",
          "iopub.status.idle": "2022-03-08T17:03:17.721577Z",
          "shell.execute_reply.started": "2022-03-08T17:03:17.693344Z",
          "shell.execute_reply": "2022-03-08T17:03:17.720926Z"
        },
        "trusted": true,
        "id": "j_5qd32whJCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model([encoder_inputs_placeholder,\n",
        "  decoder_inputs_placeholder], decoder_outputs)\n",
        "model.compile(\n",
        "    optimizer='rmsprop',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-08T17:03:17.722650Z",
          "iopub.execute_input": "2022-03-08T17:03:17.722909Z",
          "iopub.status.idle": "2022-03-08T17:03:17.736450Z",
          "shell.execute_reply.started": "2022-03-08T17:03:17.722875Z",
          "shell.execute_reply": "2022-03-08T17:03:17.735653Z"
        },
        "trusted": true,
        "id": "OZh5CNYchJCc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r = model.fit(\n",
        "    [encoder_input_sequences, decoder_input_sequences],\n",
        "    decoder_targets_one_hot,\n",
        "    batch_size=64,\n",
        "    epochs=50,\n",
        "    validation_split=0.3,\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-08T17:03:17.737713Z",
          "iopub.execute_input": "2022-03-08T17:03:17.737972Z"
        },
        "trusted": true,
        "id": "RgS2TP1qhJCd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f900a1a-fa0c-47a7-ef8a-4f760970f2bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "83/83 [==============================] - 18s 166ms/step - loss: 1.6348 - accuracy: 0.8110 - val_loss: 1.1145 - val_accuracy: 0.8334\n",
            "Epoch 2/50\n",
            "83/83 [==============================] - 10s 118ms/step - loss: 0.8488 - accuracy: 0.8776 - val_loss: 0.9470 - val_accuracy: 0.8660\n",
            "Epoch 3/50\n",
            "83/83 [==============================] - 10s 121ms/step - loss: 0.7358 - accuracy: 0.8887 - val_loss: 0.8972 - val_accuracy: 0.8742\n",
            "Epoch 4/50\n",
            "83/83 [==============================] - 10s 119ms/step - loss: 0.6835 - accuracy: 0.8937 - val_loss: 0.8597 - val_accuracy: 0.8786\n",
            "Epoch 5/50\n",
            "83/83 [==============================] - 10s 119ms/step - loss: 0.6481 - accuracy: 0.8970 - val_loss: 0.8375 - val_accuracy: 0.8761\n",
            "Epoch 6/50\n",
            "83/83 [==============================] - 10s 119ms/step - loss: 0.6183 - accuracy: 0.9012 - val_loss: 0.8138 - val_accuracy: 0.8841\n",
            "Epoch 7/50\n",
            "83/83 [==============================] - 10s 120ms/step - loss: 0.5907 - accuracy: 0.9041 - val_loss: 0.7992 - val_accuracy: 0.8876\n",
            "Epoch 8/50\n",
            "83/83 [==============================] - 10s 120ms/step - loss: 0.5646 - accuracy: 0.9066 - val_loss: 0.7934 - val_accuracy: 0.8899\n",
            "Epoch 9/50\n",
            "83/83 [==============================] - 10s 120ms/step - loss: 0.5416 - accuracy: 0.9092 - val_loss: 0.7950 - val_accuracy: 0.8890\n",
            "Epoch 10/50\n",
            "83/83 [==============================] - 10s 119ms/step - loss: 0.5191 - accuracy: 0.9116 - val_loss: 0.7646 - val_accuracy: 0.8925\n",
            "Epoch 11/50\n",
            "83/83 [==============================] - 10s 120ms/step - loss: 0.4974 - accuracy: 0.9151 - val_loss: 0.7621 - val_accuracy: 0.8955\n",
            "Epoch 12/50\n",
            "83/83 [==============================] - 10s 119ms/step - loss: 0.4757 - accuracy: 0.9176 - val_loss: 0.7439 - val_accuracy: 0.8999\n",
            "Epoch 13/50\n",
            "83/83 [==============================] - 10s 120ms/step - loss: 0.4559 - accuracy: 0.9197 - val_loss: 0.7757 - val_accuracy: 0.8932\n",
            "Epoch 14/50\n",
            "83/83 [==============================] - 10s 120ms/step - loss: 0.4362 - accuracy: 0.9220 - val_loss: 0.7396 - val_accuracy: 0.9006\n",
            "Epoch 15/50\n",
            "83/83 [==============================] - 10s 121ms/step - loss: 0.4171 - accuracy: 0.9242 - val_loss: 0.7339 - val_accuracy: 0.9009\n",
            "Epoch 16/50\n",
            "83/83 [==============================] - 10s 120ms/step - loss: 0.3991 - accuracy: 0.9261 - val_loss: 0.7427 - val_accuracy: 0.8994\n",
            "Epoch 17/50\n",
            "83/83 [==============================] - 10s 120ms/step - loss: 0.3826 - accuracy: 0.9281 - val_loss: 0.7344 - val_accuracy: 0.9028\n",
            "Epoch 18/50\n",
            "83/83 [==============================] - 10s 120ms/step - loss: 0.3663 - accuracy: 0.9301 - val_loss: 0.7156 - val_accuracy: 0.9046\n",
            "Epoch 19/50\n",
            "83/83 [==============================] - 10s 120ms/step - loss: 0.3505 - accuracy: 0.9326 - val_loss: 0.7235 - val_accuracy: 0.9029\n",
            "Epoch 20/50\n",
            "83/83 [==============================] - 10s 120ms/step - loss: 0.3341 - accuracy: 0.9347 - val_loss: 0.7172 - val_accuracy: 0.9046\n",
            "Epoch 21/50\n",
            "83/83 [==============================] - 10s 119ms/step - loss: 0.3182 - accuracy: 0.9371 - val_loss: 0.7184 - val_accuracy: 0.9035\n",
            "Epoch 22/50\n",
            "83/83 [==============================] - 10s 119ms/step - loss: 0.3039 - accuracy: 0.9393 - val_loss: 0.7250 - val_accuracy: 0.9037\n",
            "Epoch 23/50\n",
            "83/83 [==============================] - 10s 119ms/step - loss: 0.2895 - accuracy: 0.9417 - val_loss: 0.7162 - val_accuracy: 0.9050\n",
            "Epoch 24/50\n",
            "83/83 [==============================] - 10s 120ms/step - loss: 0.2760 - accuracy: 0.9442 - val_loss: 0.7249 - val_accuracy: 0.9039\n",
            "Epoch 25/50\n",
            "83/83 [==============================] - 10s 120ms/step - loss: 0.2628 - accuracy: 0.9470 - val_loss: 0.7272 - val_accuracy: 0.9049\n",
            "Epoch 26/50\n",
            "83/83 [==============================] - 10s 121ms/step - loss: 0.2498 - accuracy: 0.9495 - val_loss: 0.7152 - val_accuracy: 0.9065\n",
            "Epoch 27/50\n",
            "83/83 [==============================] - 10s 119ms/step - loss: 0.2372 - accuracy: 0.9521 - val_loss: 0.7307 - val_accuracy: 0.9045\n",
            "Epoch 28/50\n",
            "83/83 [==============================] - 10s 119ms/step - loss: 0.2252 - accuracy: 0.9548 - val_loss: 0.7323 - val_accuracy: 0.9043\n",
            "Epoch 29/50\n",
            "83/83 [==============================] - 10s 120ms/step - loss: 0.2122 - accuracy: 0.9579 - val_loss: 0.7198 - val_accuracy: 0.9068\n",
            "Epoch 30/50\n",
            "83/83 [==============================] - 10s 120ms/step - loss: 0.2003 - accuracy: 0.9606 - val_loss: 0.7230 - val_accuracy: 0.9062\n",
            "Epoch 31/50\n",
            "83/83 [==============================] - 10s 120ms/step - loss: 0.1885 - accuracy: 0.9635 - val_loss: 0.7338 - val_accuracy: 0.9051\n",
            "Epoch 32/50\n",
            "83/83 [==============================] - 10s 120ms/step - loss: 0.1765 - accuracy: 0.9663 - val_loss: 0.7293 - val_accuracy: 0.9056\n",
            "Epoch 33/50\n",
            "83/83 [==============================] - 10s 120ms/step - loss: 0.1659 - accuracy: 0.9689 - val_loss: 0.7384 - val_accuracy: 0.9050\n",
            "Epoch 34/50\n",
            "83/83 [==============================] - 10s 120ms/step - loss: 0.1559 - accuracy: 0.9718 - val_loss: 0.7443 - val_accuracy: 0.9039\n",
            "Epoch 35/50\n",
            "83/83 [==============================] - 10s 121ms/step - loss: 0.1461 - accuracy: 0.9743 - val_loss: 0.7399 - val_accuracy: 0.9068\n",
            "Epoch 36/50\n",
            "83/83 [==============================] - 10s 120ms/step - loss: 0.1374 - accuracy: 0.9764 - val_loss: 0.7424 - val_accuracy: 0.9056\n",
            "Epoch 37/50\n",
            "83/83 [==============================] - 10s 121ms/step - loss: 0.1284 - accuracy: 0.9787 - val_loss: 0.7441 - val_accuracy: 0.9045\n",
            "Epoch 38/50\n",
            "83/83 [==============================] - 10s 120ms/step - loss: 0.1194 - accuracy: 0.9811 - val_loss: 0.7398 - val_accuracy: 0.9062\n",
            "Epoch 39/50\n",
            "83/83 [==============================] - 10s 120ms/step - loss: 0.1115 - accuracy: 0.9828 - val_loss: 0.7451 - val_accuracy: 0.9058\n",
            "Epoch 40/50\n",
            "83/83 [==============================] - 10s 119ms/step - loss: 0.1032 - accuracy: 0.9850 - val_loss: 0.7427 - val_accuracy: 0.9062\n",
            "Epoch 41/50\n",
            "83/83 [==============================] - 10s 120ms/step - loss: 0.0954 - accuracy: 0.9868 - val_loss: 0.7485 - val_accuracy: 0.9061\n",
            "Epoch 42/50\n",
            "83/83 [==============================] - 10s 120ms/step - loss: 0.0879 - accuracy: 0.9885 - val_loss: 0.7479 - val_accuracy: 0.9060\n",
            "Epoch 43/50\n",
            "83/83 [==============================] - 10s 120ms/step - loss: 0.0815 - accuracy: 0.9899 - val_loss: 0.7706 - val_accuracy: 0.9045\n",
            "Epoch 44/50\n",
            "83/83 [==============================] - 10s 119ms/step - loss: 0.0749 - accuracy: 0.9913 - val_loss: 0.7617 - val_accuracy: 0.9050\n",
            "Epoch 45/50\n",
            "83/83 [==============================] - 10s 121ms/step - loss: 0.0690 - accuracy: 0.9924 - val_loss: 0.7596 - val_accuracy: 0.9057\n",
            "Epoch 46/50\n",
            "83/83 [==============================] - 10s 120ms/step - loss: 0.0629 - accuracy: 0.9936 - val_loss: 0.7660 - val_accuracy: 0.9054\n",
            "Epoch 47/50\n",
            "83/83 [==============================] - 10s 121ms/step - loss: 0.0575 - accuracy: 0.9947 - val_loss: 0.7682 - val_accuracy: 0.9054\n",
            "Epoch 48/50\n",
            "83/83 [==============================] - 10s 120ms/step - loss: 0.0522 - accuracy: 0.9955 - val_loss: 0.7716 - val_accuracy: 0.9049\n",
            "Epoch 49/50\n",
            "83/83 [==============================] - 10s 120ms/step - loss: 0.0475 - accuracy: 0.9962 - val_loss: 0.7749 - val_accuracy: 0.9035\n",
            "Epoch 50/50\n",
            "83/83 [==============================] - 10s 120ms/step - loss: 0.0433 - accuracy: 0.9967 - val_loss: 0.7773 - val_accuracy: 0.9054\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_model = Model(encoder_inputs_placeholder, encoder_states)\n",
        "\n",
        "# saving the model\n",
        "encoder_model.save('encoder')"
      ],
      "metadata": {
        "id": "cyz1TBHnpXmH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32a2f8ea-de19-4ebc-e906-8bf5b8229d1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: encoder/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: encoder/assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f62f3bcfed0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_state_input_h = Input(shape=(LSTM_NODES,))\n",
        "decoder_state_input_c = Input(shape=(LSTM_NODES,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]"
      ],
      "metadata": {
        "id": "lWqinS90pXjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_inputs_single = Input(shape=(1,))\n",
        "decoder_inputs_single_x = decoder_embedding(decoder_inputs_single)"
      ],
      "metadata": {
        "id": "b4s9jKgHpXgI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_outputs, h, c = decoder_lstm(decoder_inputs_single_x, initial_state=decoder_states_inputs)"
      ],
      "metadata": {
        "id": "ahryBtR1pXc3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_states = [h, c]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)"
      ],
      "metadata": {
        "id": "6q1gUWjupfs5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_model = Model(\n",
        "    [decoder_inputs_single] + decoder_states_inputs,\n",
        "    [decoder_outputs] + decoder_states\n",
        ")\n",
        "\n",
        "# saving the model\n",
        "decoder_model.save('decoder')"
      ],
      "metadata": {
        "id": "wdsOXUR5pfon",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2e1c887-db97-4fa5-9e82-a33fb2696804"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: decoder/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: decoder/assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f62e01ae7d0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "U_9Q0JT_qufD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc98aa85-699a-4ae5-951c-10a8288bc2c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 46)]         0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 58)]         0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 46, 100)      2000000     ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        multiple             2561536     ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    [(None, 256),        365568      ['embedding[0][0]']              \n",
            "                                 (None, 256),                                                     \n",
            "                                 (None, 256)]                                                     \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  multiple             525312      ['embedding_1[0][0]',            \n",
            "                                                                  'lstm[0][1]',                   \n",
            "                                                                  'lstm[0][2]']                   \n",
            "                                                                                                  \n",
            " dense (Dense)                  multiple             2571542     ['lstm_1[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 8,023,958\n",
            "Trainable params: 8,023,958\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx2word_input = {v:k for k, v in word2idx_inputs.items()}\n",
        "idx2word_target = {v:k for k, v in word2idx_outputs.items()}"
      ],
      "metadata": {
        "id": "P1o27piIpfZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_sentence(input_seq):\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "    target_seq = np.zeros((1, 1))\n",
        "    target_seq[0, 0] = word2idx_outputs['<sos>']\n",
        "    eos = word2idx_outputs['<eos>']\n",
        "    output_sentence = []\n",
        "\n",
        "    for _ in range(max_out_len):\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "        idx = np.argmax(output_tokens[0, 0, :])\n",
        "\n",
        "        if eos == idx:\n",
        "            break\n",
        "\n",
        "        word = ''\n",
        "\n",
        "        if idx > 0:\n",
        "            word = idx2word_target[idx]\n",
        "            output_sentence.append(word)\n",
        "\n",
        "        target_seq[0, 0] = idx\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return ' '.join(output_sentence)"
      ],
      "metadata": {
        "id": "Vzwt4F7wpSRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i = np.random.choice(len(input_sentences))\n",
        "input_seq = encoder_input_sequences[i:i+1]\n",
        "# print(input_seq)\n",
        "# print(type(input_seq))\n",
        "translation = translate_sentence(input_seq)\n",
        "# print('-')\n",
        "print('Input:', input_sentences[i])\n",
        "print('Response:', translation)\n",
        "print('Original Translation:', output_sentences[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsCI_sbqiP7x",
        "outputId": "94009b55-ab2a-4b62-98be-8448991ca069"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Name the total number of japanese for amagasaki\n",
            "Response: select count japanese from table where name = amagasaki\n",
            "Original Translation: SELECT COUNT Japanese FROM table WHERE Name = Amagasaki <eos>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = []\n",
        "for j in range(20):\n",
        "  i = np.random.choice(len(input_sentences))\n",
        "  input_seq = encoder_input_sequences[i:i+1]\n",
        "  # print(input_seq)\n",
        "  # print(type(input_seq))\n",
        "  translation = translate_sentence(input_seq)\n",
        "  # print('-')\n",
        "  # print('Input:', input_sentences[i])\n",
        "  # print('Response:', translation)\n",
        "  # print('Original Translation:', output_sentences[i])\n",
        "  lst1 = output_sentences[i].lower().split(' ')\n",
        "  lst2 = translation.split(' ')\n",
        "  score = nltk.translate.bleu_score.sentence_bleu(lst1, lst2)\n",
        "  scores.append(score)\n",
        "  # print(score)\n",
        "  # print('\\n')\n",
        "\n",
        "print('Average: ', sum(scores)/len(scores))"
      ],
      "metadata": {
        "id": "yT08xj_h2edU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6060e42-637e-440b-f1dd-fc344a3a84cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average:  0.5549612420618882\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Frontend work"
      ],
      "metadata": {
        "id": "jQ5tou6dQ2tF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reconstructed_encoder = keras.models.load_model(\"encoder\")\n",
        "\n",
        "reconstructed_encoder.compile(\n",
        "    optimizer='rmsprop',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "gfqPJwjpyVHM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbf4206d-58fe-41f1-be5a-6b95ecb5f6e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reconstructed_decoder = keras.models.load_model(\"decoder\")\n",
        "\n",
        "reconstructed_decoder.compile(\n",
        "    optimizer='rmsprop',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "gX56s2QDiHVv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "300363cd-8eaf-40a4-cb5f-47b125f3d332"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"dict1.json\", \"w\") as outfile:\n",
        "    json.dump(word2idx_outputs, outfile)\n",
        "\n",
        "with open(\"dict2.json\", \"w\") as outfile:\n",
        "    json.dump(idx2word_target, outfile)\n",
        "\n",
        "with open(\"dict3.json\", \"w\") as outfile:\n",
        "    json.dump(word2idx_inputs, outfile)"
      ],
      "metadata": {
        "id": "Dk02RORAjIuO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = open(\"dict1.json\")\n",
        "word2idx_outputs_frontend = json.load(a)\n",
        "\n",
        "b = open(\"dict2.json\")\n",
        "idx2word_target_frontend = json.load(b)\n",
        "\n",
        "c = open(\"dict3.json\")\n",
        "word2idx_inputs_frontend = json.load(c)"
      ],
      "metadata": {
        "id": "dirmovN_p2c9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_out_len"
      ],
      "metadata": {
        "id": "gBfdchzMyUo3",
        "outputId": "0bff09e4-e480-4a90-8abb-10c32d2afb33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "58"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_sentence(input_seq):\n",
        "    states_value = reconstructed_encoder.predict(input_seq)\n",
        "    target_seq = np.zeros((1, 1))\n",
        "    target_seq[0, 0] = word2idx_outputs_frontend['<sos>']\n",
        "    eos = word2idx_outputs_frontend['<eos>']\n",
        "    output_sentence = []\n",
        "    lst1 = []\n",
        "\n",
        "    for _ in range(max_out_len):\n",
        "        output_tokens, h, c = reconstructed_decoder.predict([target_seq] + states_value)\n",
        "        idx = np.argmax(output_tokens[0, 0, :])\n",
        "\n",
        "        if eos == idx:\n",
        "            break\n",
        "\n",
        "        word = ''\n",
        "\n",
        "        if idx > 0:\n",
        "            idx = str(idx)\n",
        "            word = idx2word_target_frontend[idx]\n",
        "            output_sentence.append(word)\n",
        "\n",
        "        target_seq[0, 0] = idx\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return ' '.join(output_sentence)"
      ],
      "metadata": {
        "id": "czMQQDIHiPH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"What are the students first names who have cats as pets\"\n",
        "text = \"How many people work in the HR department\"\n",
        "# text = 'Who are all of the players on the Westchester High School club team?'\n",
        "# text = 'What official languages are spoken in the country whose capital city is Canberra'\n",
        "\n",
        "\n",
        "\n",
        "def preprocess(text):\n",
        "  text1 = text.lower()\n",
        "  lst1 = text1.split(' ')\n",
        "  # print(lst1)\n",
        "  txt_seq = []\n",
        "  count = max(word2idx_inputs_frontend.values()) + 1\n",
        "  for each in lst1:\n",
        "    '''try:\n",
        "      temp = word2idx_inputs_frontend[each]\n",
        "    except:\n",
        "      temp_lst = glove_vectors.most_similar(each)\n",
        "      temp = temp_lst[0][0]'''\n",
        "    if each not in word2idx_inputs_frontend.keys():\n",
        "\n",
        "      word2idx_inputs_frontend[each] = count\n",
        "      count = count + 1\n",
        "    else:\n",
        "      temp = word2idx_inputs_frontend[each]\n",
        "    txt_seq.append(temp)\n",
        "  # print(txt_seq)\n",
        "  if len(txt_seq)<46:\n",
        "    lst2 = [[0]*(46-len(txt_seq)) + txt_seq]\n",
        "  # print(lst2)\n",
        "  translation = translate_sentence(lst2)\n",
        "  # print(translation)\n",
        "  return translation\n",
        "\n",
        "lst3 = preprocess(text)\n",
        "print(lst3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkzp7ce2i8do",
        "outputId": "bf29f5ef-c008-48b2-d6db-dbe9c1b57ed0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "select count country from table where us (in lakh income\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "BrlPB2zIi9TZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Llry82Ifi9Ox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api"
      ],
      "metadata": {
        "id": "OCgwbqo_iiHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_vectors = api.load(\"glove-wiki-gigaword-100\") "
      ],
      "metadata": {
        "id": "LCgX9bUDijph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_vectors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoOuM4lfYixy",
        "outputId": "87ae4191-aee4-40d8-cf35-7e6e57e4eb29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<gensim.models.keyedvectors.Word2VecKeyedVectors at 0x7f6032054950>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = word_vectors.most_similar(positive=['woman', 'king'], negative=['man'])"
      ],
      "metadata": {
        "id": "Iofq4qk3YRDk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "most_similar_key, similarity = result[0] "
      ],
      "metadata": {
        "id": "ETmxyd5bYd6b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"{most_similar_key}: {similarity:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUqB8Za3Yf3C",
        "outputId": "3b90d4fb-7721-4f1c-be45-2659b249a998"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "queen: 0.7699\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(word_vectors[most_similar_key])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNCIXkkDixQ6",
        "outputId": "d4aeb08f-de4f-46f6-f5aa-7aebcd3fb31f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.50045  -0.70826   0.55388   0.673     0.22486   0.60281  -0.26194\n",
            "  0.73872  -0.65383  -0.21606  -0.33806   0.24498  -0.51497   0.8568\n",
            " -0.37199  -0.58824   0.30637  -0.30668  -0.2187    0.78369  -0.61944\n",
            " -0.54925   0.43067  -0.027348  0.97574   0.46169   0.11486  -0.99842\n",
            "  1.0661   -0.20819   0.53158   0.40922   1.0406    0.24943   0.18709\n",
            "  0.41528  -0.95408   0.36822  -0.37948  -0.6802   -0.14578  -0.20113\n",
            "  0.17113  -0.55705   0.7191    0.070014 -0.23637   0.49534   1.1576\n",
            " -0.05078   0.25731  -0.091052  1.2663    1.1047   -0.51584  -2.0033\n",
            " -0.64821   0.16417   0.32935   0.048484  0.18997   0.66116   0.080882\n",
            "  0.3364    0.22758   0.1462   -0.51005   0.63777   0.47299  -0.3282\n",
            "  0.083899 -0.78547   0.099148  0.039176  0.27893   0.11747   0.57862\n",
            "  0.043639 -0.15965  -0.35304  -0.048965 -0.32461   1.4981    0.58138\n",
            " -1.132    -0.60673  -0.37505  -1.1813    0.80117  -0.50014  -0.16574\n",
            " -0.70584   0.43012   0.51051  -0.8033   -0.66572  -0.63717  -0.36032\n",
            "  0.13347  -0.56075 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "UuFcKbN48XFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xVZQ5kCF8GEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "5bFdypbXsZtE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BLEUscore = nltk.translate.bleu_score.sentence_bleu([pre], post)"
      ],
      "metadata": {
        "id": "iiC7-hqrsaPU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}